import logging
import math
import random
import time
import pandas as pd
from sqlalchemy import text
from dbhelp import get_engine, DB_CONFIG

# === æ—¥å¿—é…ç½® ===
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


# === å·¥å…·å‡½æ•° ===
def random_point(lat_center, lon_center, radius_km=1000):
    """
    ç”Ÿæˆæ–¹åœ† radius_km å…¬é‡Œå†…éšæœºåæ ‡ï¼ˆWGS84ï¼Œç»çº¬åº¦ï¼‰
    """
    radius_deg = radius_km / 111.0  # è¿‘ä¼¼æ¢ç®—
    angle = random.uniform(0, 2 * math.pi)
    r = radius_deg * math.sqrt(random.uniform(0, 1))
    lat = lat_center + r * math.cos(angle)
    lon = lon_center + r * math.sin(angle) / math.cos(math.radians(lat_center))
    return round(lat, 6), round(lon, 6)


def convert_numpy_types(obj):
    """
    å°† numpy æ•°æ®ç±»å‹è½¬æ¢ä¸º Python åŸç”Ÿç±»å‹
    """
    if hasattr(obj, 'item'):
        return obj.item()
    elif isinstance(obj, dict):
        return {k: convert_numpy_types(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [convert_numpy_types(item) for item in obj]
    else:
        return obj


def build_region_hierarchy(df_region):
    """
    æ„å»ºåŒºåŸŸå±‚çº§å…³ç³»ï¼ˆä¿æŒåŸå§‹åˆ—ï¼ŒåŒ…æ‹¬ latitude/longitude å¦‚æœå­˜åœ¨ï¼‰
    è¿”å› dictï¼ŒåŒ…å« DataFrame å¯¹è±¡å’Œæ˜ å°„
    """
    level_counts = df_region['level'].value_counts()
    logger.info(f"åŒºåŸŸå±‚çº§åˆ†å¸ƒ: {level_counts.to_dict()}")

    hierarchy = {}

    for prov_level in [1, '1', 'province']:
        if prov_level in df_region['level'].values:
            provinces = df_region[df_region['level'] == prov_level]
            hierarchy['provinces'] = provinces
            logger.info(f"æ‰¾åˆ°çœä»½å±‚çº§: {prov_level}, æ•°é‡: {len(provinces)}")
            break

    for city_level in [2, '2', 'city']:
        if city_level in df_region['level'].values:
            cities = df_region[df_region['level'] == city_level]
            hierarchy['cities'] = cities
            city_to_province = cities.set_index('region_id')['parent_id'].to_dict()
            hierarchy['city_to_province'] = city_to_province
            logger.info(f"æ‰¾åˆ°åŸå¸‚å±‚çº§: {city_level}, æ•°é‡: {len(cities)}")
            break

    for area_level in [3, '3', 'area', 'district']:
        if area_level in df_region['level'].values:
            areas = df_region[df_region['level'] == area_level]
            hierarchy['areas'] = areas
            area_to_city = areas.set_index('region_id')['parent_id'].to_dict()
            hierarchy['area_to_city'] = area_to_city
            logger.info(f"æ‰¾åˆ°åŒºåŸŸå±‚çº§: {area_level}, æ•°é‡: {len(areas)}")
            break

    if not hierarchy:
        top_levels = level_counts.head(3).index.tolist()
        if len(top_levels) >= 1:
            hierarchy['provinces'] = df_region[df_region['level'] == top_levels[0]]
        if len(top_levels) >= 2:
            hierarchy['cities'] = df_region[df_region['level'] == top_levels[1]]
        if len(top_levels) >= 3:
            hierarchy['areas'] = df_region[df_region['level'] == top_levels[2]]

    return hierarchy


def get_random_location(hierarchy):
    """
    ä»åŒºåŸŸå±‚çº§ä¸­éšæœºé€‰æ‹©ä¸€ä¸ªä½ç½®å¹¶å°½å¯èƒ½è¿”å›è¯¥åŒºåŸŸçš„ç»çº¬åº¦ä¸­å¿ƒã€‚
    è¿”å›: province_id, city_id, region_id, address_str, lat_center, lon_center
    å¦‚æœæŸä¸€çº§æ²¡æœ‰ç»çº¬åº¦ï¼Œåˆ™å›é€€åˆ°ä¸Šä¸€çº§ï¼›è‹¥å…¨éƒ¨ç¼ºå¤±ï¼Œè¿”å› (None, None)
    """
    provinces = hierarchy.get('provinces')
    cities = hierarchy.get('cities')
    areas = hierarchy.get('areas')

    if provinces is None or provinces.empty:
        return None, None, None, "Unknown Location", None, None

    prov = provinces.sample(1).iloc[0]

    # åŸå¸‚é€‰æ‹©
    if cities is not None and not cities.empty:
        province_cities = cities[cities['parent_id'] == prov['region_id']]
        if not province_cities.empty:
            city = province_cities.sample(1).iloc[0]
        else:
            city = cities.sample(1).iloc[0]
    else:
        city = {
            'region_id': int(prov['region_id']) * 100,
            'name_en': f"City of {prov.get('name_en', prov.get('name', ''))}",
            'parent_id': int(prov['region_id'])
        }

    # åŒºåŸŸé€‰æ‹©
    if areas is not None and not areas.empty:
        # æ³¨æ„ï¼šcity å¯èƒ½æ˜¯ Series æˆ– dict
        city_id_val = city['region_id'] if isinstance(city, dict) else city['region_id']
        city_areas = areas[areas['parent_id'] == city_id_val]
        if not city_areas.empty:
            area = city_areas.sample(1).iloc[0]
        else:
            area = areas.sample(1).iloc[0]
    else:
        area = {
            'region_id': int(city['region_id']) * 100,
            'name_en': f"Area of {city.get('name_en', city.get('name', ''))}",
            'parent_id': int(city['region_id'])
        }

    # ç»„åˆåœ°å€
    address_parts = []
    for node in (prov, city, area):
        if isinstance(node, dict):
            name = node.get('name_en') or node.get('name')
        else:
            name = node.get('name_en') if 'name_en' in node else node.get('name') if 'name' in node else None
        if name:
            address_parts.append(str(name))

    address_str = " ".join(address_parts) if address_parts else "Unknown Location"

    # ä¼˜å…ˆä» area -> city -> province è·å–åæ ‡
    def extract_latlon(node):
        if node is None:
            return None, None
        if isinstance(node, dict):
            lat = node.get('latitude') or node.get('lat')
            lon = node.get('longitude') or node.get('lon')
        else:
            lat = node.get('latitude') if 'latitude' in node else (node.get('lat') if 'lat' in node else None)
            lon = node.get('longitude') if 'longitude' in node else (node.get('lon') if 'lon' in node else None)
        # å¤„ç† pandas çš„ NaN
        if pd.isna(lat) or pd.isna(lon):
            return None, None
        try:
            return float(lat), float(lon)
        except Exception:
            return None, None

    lat_center, lon_center = extract_latlon(area)
    if lat_center is None:
        lat_center, lon_center = extract_latlon(city)
    if lat_center is None:
        lat_center, lon_center = extract_latlon(prov)

    # å¦‚æœä¾ç„¶æ²¡æœ‰åæ ‡ï¼Œè¿”å› None
    if lat_center is None or lon_center is None:
        return int(prov['region_id']), int(city['region_id']), int(area['region_id']), address_str, None, None

    return int(prov['region_id']), int(city['region_id']), int(area['region_id']), address_str, lat_center, lon_center


# === ä¸»æµç¨‹ ===
def main(batch_size=100000):
    logger.info("ğŸ”„ è¿æ¥æ•°æ®åº“...")
    engine = get_engine(DB_CONFIG)
    logger.info("âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ")

    with engine.connect() as conn:
        # 1ï¸âƒ£ æ£€æŸ¥è®¾å¤‡è¡¨ç»“æ„
        logger.info("ğŸ”„ æ£€æŸ¥ dev_device_instance è¡¨ç»“æ„...")
        device_columns = conn.execute(text("""
            SELECT column_name 
            FROM information_schema.columns 
            WHERE table_name = 'dev_device_instance'
            ORDER BY ordinal_position
        """)).fetchall()

        device_columns = [col[0] for col in device_columns]
        logger.info(f"è®¾å¤‡è¡¨å­—æ®µæ•°é‡: {len(device_columns)}")

        lat_fields = [col for col in device_columns if 'lat' in col.lower()]
        lon_fields = [col for col in device_columns if 'lon' in col.lower()]

        logger.info(f"çº¬åº¦å­—æ®µ: {lat_fields}")
        logger.info(f"ç»åº¦å­—æ®µ: {lon_fields}")

        lat_field = lat_fields[0] if lat_fields else None
        lon_field = lon_fields[0] if lon_fields else None

        if lat_field and lon_field:
            coord_fields = f"{lat_field}, {lon_field}"
            logger.info(f"ä½¿ç”¨åæ ‡å­—æ®µ: {lat_field}, {lon_field}")
        else:
            coord_fields = "id"
            logger.warning("âš ï¸ æœªæ‰¾åˆ°åæ ‡å­—æ®µï¼Œå°†ä½¿ç”¨é»˜è®¤åæ ‡")

        # 2ï¸âƒ£ è¯»å–åŒºåŸŸæ•°æ®ï¼ˆåŒ…å« latitude/longitudeï¼‰
        logger.info("ğŸ”„ è¯»å– alabo_region åŒºåŸŸè¡¨...")
        df_region = pd.DataFrame(conn.execute(
            text("SELECT region_id, parent_id, name_en, level, latitude, longitude FROM alabo_region")
        ).mappings().all())

        if df_region.empty:
            logger.error("âŒ alabo_region è¡¨ä¸ºç©ºï¼Œæ— æ³•ç»§ç»­æ‰§è¡Œ")
            return

        logger.info(f"è¯»å–åˆ°åŒºåŸŸæ•°æ®: {len(df_region)} æ¡")

        hierarchy = build_region_hierarchy(df_region)

        if 'provinces' not in hierarchy or hierarchy['provinces'].empty:
            logger.error("âŒ æ²¡æœ‰æ‰¾åˆ°çœä»½æ•°æ®ï¼Œæ— æ³•ç»§ç»­")
            return

        # 3ï¸âƒ£ æ¸…ç©ºå…³é”®å­—æ®µ
        logger.info("ğŸ”„ æ¸…ç©º dev_device_instance çš„å…³é”®å­—æ®µ...")
        conn.execute(text("""
            UPDATE dev_device_instance
            SET province_id=NULL, city_id=NULL, region_id=NULL,
                install_latitude=NULL, install_longitude=NULL,
                install_address=NULL, address=NULL
        """))
        conn.commit()
        logger.info("âœ… æ¸…ç©ºå®Œæˆ")

        # 4ï¸âƒ£ å¤„ç†è®¾å¤‡æ•°æ®åˆ†æ‰¹
        total_devices = conn.execute(text("SELECT COUNT(*) FROM dev_device_instance")).scalar()
        logger.info(f"ğŸ“¦ dev_device_instance æ€»è®°å½•æ•°: {total_devices}")

        estimated_batches = (total_devices + batch_size - 1) // batch_size
        logger.info(f"é¢„è®¡å¤„ç†æ‰¹æ¬¡: {estimated_batches}")

        offset = 0
        start_time = time.time()
        batch_index = 1
        processed_count = 0

        while offset < total_devices:
            batch_start_time = time.time()
            logger.info(
                f"ğŸ”„ å¼€å§‹å¤„ç†ç¬¬ {batch_index} æ‰¹æ•°æ® (offset={offset}, è¿›åº¦: {processed_count}/{total_devices})...")

            devices = pd.DataFrame(conn.execute(
                text(
                    f"SELECT id, {coord_fields} FROM dev_device_instance ORDER BY id LIMIT {batch_size} OFFSET {offset}")
            ).mappings().all())

            if devices.empty:
                break

            update_records = []
            for _, row in devices.iterrows():
                try:
                    province_id, city_id, region_id, address, lat_center, lon_center = get_random_location(hierarchy)
                    if province_id is None:
                        continue

                    # ä¼˜å…ˆä½¿ç”¨åŒºåŸŸä¸­å¿ƒåæ ‡ï¼ˆarea -> city -> provinceï¼‰ï¼Œè‹¥ä¸å­˜åœ¨åˆ™ä½¿ç”¨è®¾å¤‡åŸå§‹åæ ‡ï¼Œæœ€åé€€å›åˆ°åŒ—äº¬
                    if lat_center is None or lon_center is None:
                        # å¦‚æœè®¾å¤‡è¡¨å­˜åœ¨åæ ‡å­—æ®µï¼Œå°è¯•ä½¿ç”¨è®¾å¤‡å·²æœ‰åæ ‡
                        if lat_field and lon_field and lat_field in row and lon_field in row and pd.notna(row[lat_field]) and pd.notna(row[lon_field]):
                            try:
                                lat_center = float(row[lat_field])
                                lon_center = float(row[lon_field])
                            except Exception:
                                lat_center, lon_center = 39.9042, 116.4074
                        else:
                            # é€€å›åˆ°åŒ—äº¬å¸‚ä¸­å¿ƒï¼ˆä»…ä½œä¸ºæœ€åçš„å…œåº•ï¼‰
                            lat_center, lon_center = 39.9042, 116.4074

                    lat, lon = random_point(lat_center, lon_center, radius_km=100)

                    record = {
                        'id': str(row['id']),
                        'province_id': province_id,
                        'city_id': city_id,
                        'region_id': region_id,
                        'install_latitude': float(lat),
                        'install_longitude': float(lon),
                        'address': str(address),
                        'install_address': str(address)
                    }

                    update_records.append(record)
                except Exception as e:
                    logger.error(f"å¤„ç†è®¾å¤‡ {row['id']} æ—¶å‡ºé”™: {e}")
                    continue

            if not update_records:
                logger.warning(f"ç¬¬ {batch_index} æ‰¹æ²¡æœ‰ç”Ÿæˆæ›´æ–°è®°å½•")
                offset += batch_size
                batch_index += 1
                continue

            try:
                update_sql = """
                    UPDATE dev_device_instance
                    SET province_id = :province_id,
                        city_id = :city_id,
                        region_id = :region_id,
                        install_latitude = :install_latitude,
                        install_longitude = :install_longitude,
                        address = :address,
                        install_address = :install_address
                    WHERE id = :id
                """

                converted_records = [convert_numpy_types(record) for record in update_records]

                chunk_size = 10000
                for i in range(0, len(converted_records), chunk_size):
                    chunk = converted_records[i:i + chunk_size]
                    conn.execute(text(update_sql), chunk)
                    conn.commit()

                batch_duration = time.time() - batch_start_time
                processed_count += len(update_records)
                logger.info(f"âœ… ç¬¬ {batch_index} æ‰¹å®Œæˆï¼Œæ›´æ–° {len(update_records)} æ¡è®°å½•ï¼Œè€—æ—¶ {batch_duration:.2f} ç§’")

            except Exception as e:
                logger.error(f"æ‰¹é‡æ›´æ–°ç¬¬ {batch_index} æ‰¹æ—¶å‡ºé”™: {e}")
                conn.rollback()

            offset += batch_size
            batch_index += 1

        total_duration = time.time() - start_time
        logger.info(f"\nğŸ¯ å…¨éƒ¨å®Œæˆï¼Œè€—æ—¶ {total_duration:.2f} ç§’")
        logger.info(f"âš¡ å¹³å‡é€Ÿåº¦: {processed_count / max(total_duration, 0.001):.1f} æ¡/ç§’")
        logger.info(f"ğŸ“Š æ€»å¤„ç†è®°å½•: {processed_count}/{total_devices}")


if __name__ == "__main__":
    main()
