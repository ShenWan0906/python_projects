import logging
import time
import re
import pandas as pd
from concurrent.futures import ThreadPoolExecutor, as_completed
from sqlalchemy import text
from deep_translator import GoogleTranslator
from dbhelp import get_engine, DB_CONFIG

# === æ—¥å¿—é…ç½® ===
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)

# === å·¥å…·å‡½æ•° ===
def contains_arabic(text: str) -> bool:
    """åˆ¤æ–­å­—ç¬¦ä¸²ä¸­æ˜¯å¦åŒ…å«é˜¿æ‹‰ä¼¯æ–‡å­—ç¬¦"""
    if not text:
        return False
    return bool(re.search(r'[\u0600-\u06FF\u0750-\u077F\u08A0-\u08FF]', text))

def needs_translation(name_ar: str) -> bool:
    """åˆ¤æ–­å½“å‰ name_ar æ˜¯å¦éœ€è¦ç¿»è¯‘"""
    if pd.isna(name_ar) or name_ar.strip() == "":
        return True
    # å¦‚æœæ²¡æœ‰é˜¿æ‹‰ä¼¯æ–‡å­—ç¬¦ï¼Œè¯´æ˜è¿˜æ²¡ç¿»è¯‘æˆåŠŸ
    if not contains_arabic(name_ar):
        return True
    return False

def translate_text(row, translator, max_retries=5):
    """ç¿»è¯‘è‹±æ–‡ä¸ºé˜¿æ‹‰ä¼¯æ–‡ï¼Œå¸¦é‡è¯•"""
    region_id = row["region_id"]
    name_en = row["name_en"]

    if not name_en or pd.isna(name_en):
        logger.warning(f"âš ï¸ region_id={region_id} çš„ name_en ä¸ºç©ºï¼Œè·³è¿‡ã€‚")
        return region_id, "", name_en

    for attempt in range(max_retries):
        try:
            result = translator.translate(name_en).strip()
            if contains_arabic(result):
                return region_id, result, name_en
            else:
                logger.warning(f"âš ï¸ ç¿»è¯‘ä»ä¸ºè‹±æ–‡æˆ–å¼‚å¸¸ï¼Œregion_id={region_id}, result='{result}'")
        except Exception as e:
            logger.warning(f"âš ï¸ ç¿»è¯‘å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}) - region_id={region_id}: {e}")
        if attempt < max_retries - 1:
            time.sleep(2)  # é‡è¯•é—´éš”
    logger.error(f"âŒ ç¿»è¯‘æœ€ç»ˆå¤±è´¥ region_id={region_id}, name_en='{name_en}'")
    return region_id, "", name_en

# === ä¸»æµç¨‹ ===
def main(batch_size=100, max_workers=5, test_mode=True):
    logger.info("ğŸ”„ è¿æ¥æ•°æ®åº“...")
    engine = get_engine(DB_CONFIG)
    logger.info("âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ")

    translator = GoogleTranslator(source="auto", target="ar")

    with engine.connect() as conn:
        # è¯»å–æ‰€æœ‰æ•°æ®
        df_region = pd.DataFrame(conn.execute(
            text("SELECT region_id, name_en, name_ar FROM alabo_region")
        ).mappings().all())

        # åªå¤„ç†éœ€è¦é‡æ–°ç¿»è¯‘çš„è®°å½•
        records_to_translate = df_region[df_region["name_ar"].apply(needs_translation)]
        total_records = len(records_to_translate)
        logger.info(f"ğŸ“Š å¾…ç¿»è¯‘è®°å½•æ•°: {total_records} / {len(df_region)}")

        if total_records == 0:
            logger.info("âœ… æ— éœ€ç¿»è¯‘ï¼Œæ‰€æœ‰æ•°æ®å·²æ­£ç¡®ç¿»è¯‘ã€‚")
            return

        start_time = time.time()
        processed_count = 0
        batch_index = 1

        for i in range(0, total_records, batch_size):
            batch = records_to_translate.iloc[i:i + batch_size]
            logger.info(f"ğŸŒ€ å¼€å§‹å¤„ç†ç¬¬ {batch_index} æ‰¹ ({i} ~ {i + len(batch)}) ...")

            translated_results = []
            with ThreadPoolExecutor(max_workers=max_workers) as executor:
                futures = {executor.submit(translate_text, row, translator): row["region_id"] for _, row in batch.iterrows()}
                for future in as_completed(futures):
                    region_id, name_ar, name_en = future.result()
                    if name_ar:
                        translated_results.append({"region_id": region_id, "name_en": name_en, "name_ar": name_ar})

            # æµ‹è¯•æ¨¡å¼ï¼šæ‰“å°ç¿»è¯‘ç»“æœï¼Œä¸æ›´æ–°æ•°æ®åº“
            if test_mode:
                for rec in translated_results:
                    print(f"region_id={rec['region_id']}, name_en='{rec['name_en']}', name_ar='{rec['name_ar']}'")
            else:
                # æ‰¹é‡æ›´æ–°æ•°æ®åº“
                if translated_results:
                    try:
                        update_sql = """
                            UPDATE alabo_region
                            SET name_ar = :name_ar
                            WHERE region_id = :region_id
                        """
                        conn.execute(text(update_sql), translated_results)
                        conn.commit()
                        processed_count += len(translated_results)
                        logger.info(f"âœ… ç¬¬ {batch_index} æ‰¹å®Œæˆï¼Œæ›´æ–° {len(translated_results)} æ¡è®°å½•")
                    except Exception as e:
                        conn.rollback()
                        logger.error(f"âŒ ç¬¬ {batch_index} æ‰¹æ›´æ–°å¤±è´¥: {e}")

            # é˜²æ­¢ API é™é€Ÿ
            if i + batch_size < total_records:
                logger.info("â³ ç­‰å¾… 5 ç§’é˜²æ­¢è¢«é™é€Ÿ...")
                time.sleep(5)

            batch_index += 1

        total_duration = time.time() - start_time
        logger.info("ğŸ¯ ç¿»è¯‘å®Œæˆ")
        if not test_mode:
            logger.info(f"ğŸ“Š æˆåŠŸç¿»è¯‘è®°å½•: {processed_count}/{total_records}")
        logger.info(f"â±ï¸ æ€»è€—æ—¶: {total_duration:.2f} ç§’")

if __name__ == "__main__":
    # test_mode=True åªæ‰“å°ç»“æœï¼Œä¸æ›´æ–°æ•°æ®åº“
    main(batch_size=100, max_workers=5, test_mode=True)
